{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83769c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'clip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mvutils\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mclip\u001b[39;00m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# --- 1. Poisoner Class --- #\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMultiModelEmbeddingPoisoner\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'clip'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt \n",
    "import clip \n",
    "\n",
    "# --- 1. Poisoner Class --- #\n",
    "class MultiModelEmbeddingPoisoner(nn.Module):\n",
    "    def __init__(self, models, epsilon=0.03, targeted=False, target_embeddings=None):\n",
    "        super(MultiModelEmbeddingPoisoner, self).__init__()\n",
    "        self.models = [m.eval() for m in models]\n",
    "        self.epsilon = epsilon\n",
    "        self.targeted = targeted\n",
    "        self.target_embeddings = target_embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.clone().detach().requires_grad_(True)\n",
    "        total_grad = torch.zeros_like(x)\n",
    "\n",
    "        for i, model in enumerate(self.models):\n",
    "            emb = model(x)\n",
    "\n",
    "            if self.targeted:\n",
    "                assert self.target_embeddings is not None and len(self.target_embeddings) == len(self.models), \\\n",
    "                    \"Provide one target embedding per model.\"\n",
    "                target_emb = self.target_embeddings[i]\n",
    "                loss = -F.cosine_similarity(emb, target_emb).mean()\n",
    "            else:\n",
    "                loss = torch.norm(emb, p=2)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x, retain_graph=True, create_graph=False)[0]\n",
    "            total_grad += grad\n",
    "\n",
    "        avg_grad = total_grad / len(self.models)\n",
    "        x_adv = x + self.epsilon * avg_grad.sign()\n",
    "        x_adv = torch.clamp(x_adv, 0, 1)\n",
    "\n",
    "        return x_adv.detach()\n",
    "\n",
    "\n",
    "# --- 2. Load Real Pretrained Face Models --- #\n",
    "def load_face_models():\n",
    "    from facenet_pytorch import InceptionResnetV1\n",
    "    import timm\n",
    "\n",
    "    model1 = InceptionResnetV1(pretrained='vggface2').eval() \n",
    "    # model1, preprocess = clip.load(\"ViT-B/32\", device=\"cuda\", jit=False)\n",
    "    model2 = timm.create_model('resnet18', pretrained=True)\n",
    "    model2.fc = nn.Identity()\n",
    "    model3 = timm.create_model('tf_efficientnet_b0', pretrained=True)\n",
    "    model3.classifier = nn.Identity()\n",
    "\n",
    "    return [model1, model2, model3]\n",
    "\n",
    "\n",
    "\n",
    "def cloak_single_image(image_path):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    models_list = load_face_models()\n",
    "    models_list = [m.to(device) for m in models_list]\n",
    "\n",
    "    poisoner = MultiModelEmbeddingPoisoner(models=models_list, epsilon=0.03).to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    x = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Cloak the image\n",
    "    x_adv = poisoner(x)\n",
    "\n",
    "    # Get embeddings for cosine similarity calculation\n",
    "    original_embeddings = [model(x) for model in models_list]\n",
    "    cloaked_embeddings = [model(x_adv) for model in models_list]\n",
    "\n",
    "    # Calculate cosine similarity for each model\n",
    "    cosine_similarities = []\n",
    "    for orig_emb, cloaked_emb in zip(original_embeddings, cloaked_embeddings):\n",
    "        similarity = F.cosine_similarity(orig_emb, cloaked_emb).mean().item()\n",
    "        cosine_similarities.append(similarity)\n",
    "\n",
    "    # Convert tensors to CPU for visualization\n",
    "    x = x.cpu().detach()\n",
    "    x_adv = x_adv.cpu().detach()\n",
    "\n",
    "    # Convert to numpy arrays for plotting\n",
    "    x = x.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    x_adv = x_adv.squeeze(0).permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Plot the original and cloaked images side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Display cloaked image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_adv)\n",
    "    plt.title(\"Cloaked Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Print Cosine Similarities for each model\n",
    "    for i, similarity in enumerate(cosine_similarities):\n",
    "        print(f\"Cosine Similarity for model {i+1}: {similarity:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_path = \"C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\Untrainable_AI\\\\Test.jpg\" \n",
    "    cloak_single_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec43dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import InceptionResnetV1\n",
    "import timm\n",
    "model=InceptionResnetV1(pretrained='vggface2').eval() \n",
    "torch.save(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444e391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
